{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TU71hHaX6pRv"
      },
      "outputs": [],
      "source": [
        "#Building a NLP NMT English to German using RNN technique as well as Attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rInWzbwg61VA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
        "                               extract=True)\n",
        "text = (Path(path).with_name(\"spa-eng\")/\"spa.txt\").read_text()\n",
        "\n",
        "\n",
        "# import requests\n",
        "# import tensorflow as tf\n",
        "# from pathlib import Path\n",
        "# url = 'https://www.manythings.org/anki/deu-eng.zip'\n",
        "# headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
        "\n",
        "# r = requests.get(url, headers=headers)\n",
        "# # save the file:\n",
        "# # path = tf.keras.utils.get_file(\"deu-eng.zip\", origin=url, extract=True)\n",
        "# open('my_file.zip', 'wb').write(r.content)\n",
        "# # text = (Path(path).with_name(\"deu-eng\")/\"deu.txt\").read_text()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# open('my_file.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TzDhIiQ2Arnm"
      },
      "outputs": [],
      "source": [
        "#Now we shall remove some specific tokens present only in spanish language like inverted exclamation marks, etc\n",
        "import numpy as np\n",
        "\n",
        "# text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z7YdHSfEBUva"
      },
      "outputs": [],
      "source": [
        "#Creating Textvectorization layets, one per language\n",
        "vocab_size = 1000\n",
        "max_length = 50\n",
        "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length\n",
        ")\n",
        "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length\n",
        ")\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfDbqxaeBfJh",
        "outputId": "fd3b8091-118e-4054-c107-d0eafbfb6a58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AC-_OW-SJlL",
        "outputId": "aeb9651d-4119-4071-e0f4-d0300a206fc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vec_layer_es.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2sdFAoEnSLdE"
      },
      "outputs": [],
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r8O-4h_XUI22"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5VfWKbKXUNfI"
      },
      "outputs": [],
      "source": [
        "#Encoding the sentences and embedding layer for each language\n",
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
        "\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z59CuRtKUPSz"
      },
      "outputs": [],
      "source": [
        "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "86Gyws5IVd4a"
      },
      "outputs": [],
      "source": [
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-xQNqwXvVsv7"
      },
      "outputs": [],
      "source": [
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGyhGPOnYVYD",
        "outputId": "737f6882-adb4-4a46-eb8d-20df5e59982f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x236c844ab60>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18FyP-VeXZNf",
        "outputId": "d111d4c7-89b6-4a2d-ff36-de022195328b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3125/3125 [==============================] - 72s 21ms/step - loss: 0.4122 - accuracy: 0.4290 - val_loss: 0.3080 - val_accuracy: 0.5234\n",
            "Epoch 2/5\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.2675 - accuracy: 0.5689 - val_loss: 0.2410 - val_accuracy: 0.6003\n",
            "Epoch 3/5\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.2112 - accuracy: 0.6388 - val_loss: 0.2090 - val_accuracy: 0.6440\n",
            "Epoch 4/5\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.1779 - accuracy: 0.6839 - val_loss: 0.1947 - val_accuracy: 0.6640\n",
            "Epoch 5/5\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.1544 - accuracy: 0.7174 - val_loss: 0.1874 - val_accuracy: 0.6749\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x236d6335fc0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Lets create a model now\n",
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=5, validation_data=((X_valid, X_valid_dec), Y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8jSpit3bYJp4"
      },
      "outputs": [],
      "source": [
        "#Now we can not use model.predict here as the decoder also expects inputs from previous predictions\n",
        "#Now we shall make a fucntion to feed the decoder as well\n",
        "\n",
        "def translate(sentence_en):\n",
        "  translation = \"\"\n",
        "  for word_idx in range(max_length):\n",
        "    X = np.array([sentence_en]) #encoder input\n",
        "    X_dec = np.array([\"startofseq \" + translation])\n",
        "    y_proba = model.predict((X, X_dec))[0, word_idx]\n",
        "    predicted_word_id = np.argmax(y_proba)\n",
        "    predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "    if predicted_word == \"endofseq\":\n",
        "      break\n",
        "    translation += \" \" + predicted_word\n",
        "  return translation.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "T98-bfUNaWhW",
        "outputId": "b6bfd3c0-e60b-4050-ad36-88a7e53c4c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'esto es amor'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(\"This is love.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extra code – a basic implementation of beam search\n",
        "\n",
        "def beam_search(sentence_en, beam_width, verbose=False):\n",
        "    X = np.array([sentence_en])  # encoder input\n",
        "    X_dec = np.array([\"startofseq\"])  # decoder input\n",
        "    y_proba = model.predict((X, X_dec))[0, 0]  # first token's probas\n",
        "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
        "    top_translations = [  # list of best (log_proba, translation)\n",
        "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
        "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
        "    ]\n",
        "    \n",
        "    # extra code – displays the top first words in verbose mode\n",
        "    if verbose:\n",
        "        print(\"Top first words:\", top_translations)\n",
        "\n",
        "    for idx in range(1, max_length):\n",
        "        candidates = []\n",
        "        for log_proba, translation in top_translations:\n",
        "            if translation.endswith(\"endofseq\"):\n",
        "                candidates.append((log_proba, translation))\n",
        "                continue  # translation is finished, so don't try to extend it\n",
        "            X = np.array([sentence_en])  # encoder input\n",
        "            X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "            y_proba = model.predict((X, X_dec))[0, idx]  # last token's proba\n",
        "            for word_id, word_proba in enumerate(y_proba):\n",
        "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
        "                candidates.append((log_proba + np.log(word_proba),\n",
        "                                   f\"{translation} {word}\"))\n",
        "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
        "\n",
        "        # extra code – displays the top translation so far in verbose mode\n",
        "        if verbose:\n",
        "            print(\"Top translations so far:\", top_translations)\n",
        "\n",
        "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
        "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'amo los gatos y gatos'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – shows how the model making an error\n",
        "sentence_en = \"I love cats and dogs\"\n",
        "translate(sentence_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Top first words: [(-1.1666902, 'amo'), (-1.3326418, 'me'), (-2.1916459, '[UNK]')]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Top translations so far: [(-1.4207265, 'amo los'), (-1.7773826, 'me encanta'), (-2.64506, '[UNK] los')]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Top translations so far: [(-1.7322148, 'amo los gatos'), (-2.4327912, 'me encanta el'), (-2.9497573, '[UNK] los gatos')]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Top translations so far: [(-2.229721, 'amo los gatos y'), (-3.1193464, 'me encanta el amor'), (-3.3642082, 'amo los gatos de')]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Top translations so far: [(-3.197341, 'amo los gatos y gatos'), (-3.4155998, 'me encanta el amor y'), (-3.830542, 'amo los gatos de amor')]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Top translations so far: [(-3.3064783, 'amo los gatos y gatos endofseq'), (-4.3385696, 'me encanta el amor y a'), (-4.806133, 'amo los gatos de amor a')]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Top translations so far: [(-3.3064783, 'amo los gatos y gatos endofseq'), (-4.732403, 'me encanta el amor y a los'), (-6.0797, 'amo los gatos de amor a los')]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Top translations so far: [(-3.3064783, 'amo los gatos y gatos endofseq'), (-5.32454, 'me encanta el amor y a los perros'), (-5.551535, 'me encanta el amor y a los gatos')]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Top translations so far: [(-3.3064783, 'amo los gatos y gatos endofseq'), (-5.3356237, 'me encanta el amor y a los perros endofseq'), (-5.5651402, 'me encanta el amor y a los gatos endofseq')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'amo los gatos y gatos'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# extra code – shows how beam search can help\n",
        "beam_search(sentence_en, beam_width=3, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "encoder = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extra code – this part of the model is exactly the same as earlier\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
        "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
        "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)\n",
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_layer = tf.keras.layers.Attention()\n",
        "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(attention_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3125/3125 [==============================] - 92s 27ms/step - loss: 0.1636 - accuracy: 0.7167 - val_loss: 0.1818 - val_accuracy: 0.6944\n",
            "Epoch 2/5\n",
            "3125/3125 [==============================] - 89s 28ms/step - loss: 0.1493 - accuracy: 0.7363 - val_loss: 0.1800 - val_accuracy: 0.6967\n",
            "Epoch 3/5\n",
            "3125/3125 [==============================] - 85s 27ms/step - loss: 0.1375 - accuracy: 0.7532 - val_loss: 0.1797 - val_accuracy: 0.7019\n",
            "Epoch 4/5\n",
            "3125/3125 [==============================] - 87s 28ms/step - loss: 0.1281 - accuracy: 0.7664 - val_loss: 0.1805 - val_accuracy: 0.7024\n",
            "Epoch 5/5\n",
            "3125/3125 [==============================] - 81s 26ms/step - loss: 0.1193 - accuracy: 0.7798 - val_loss: 0.1835 - val_accuracy: 0.7022\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x237b1e1f100>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=5,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'me gusta el fútbol y también ir a la playa'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "translate(\"I like soccer and also going to the beach\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Top first words: [(-0.31683892, 'me'), (-2.3549259, 'yo'), (-2.8721812, 'prefiero')]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Top translations so far: [(-0.32778606, 'me gusta'), (-2.5895562, 'yo me'), (-3.2702641, 'prefiero fútbol')]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Top translations so far: [(-0.8119446, 'me gusta el'), (-2.6010826, 'yo me gusta'), (-2.7695754, 'me gusta la')]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Top translations so far: [(-0.8122299, 'me gusta el fútbol'), (-2.7739117, 'me gusta la fútbol'), (-3.1109324, 'yo me gusta el')]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Top translations so far: [(-0.81692344, 'me gusta el fútbol y'), (-2.7775795, 'me gusta la fútbol y'), (-3.111212, 'yo me gusta el fútbol')]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Top translations so far: [(-1.268604, 'me gusta el fútbol y también'), (-2.9715037, 'me gusta la fútbol y también'), (-3.1160407, 'yo me gusta el fútbol y')]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Top translations so far: [(-2.3784423, 'me gusta el fútbol y también ir'), (-3.5956879, 'me gusta el fútbol y también va'), (-3.6387482, 'yo me gusta el fútbol y también')]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Top translations so far: [(-2.4520779, 'me gusta el fútbol y también ir a'), (-3.6538622, 'me gusta el fútbol y también va a'), (-4.4797206, 'yo me gusta el fútbol y también ir')]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Top translations so far: [(-2.4652216, 'me gusta el fútbol y también ir a la'), (-3.768089, 'me gusta el fútbol y también va a la'), (-4.5505285, 'yo me gusta el fútbol y también ir a')]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Top translations so far: [(-2.467035, 'me gusta el fútbol y también ir a la playa'), (-3.7697654, 'me gusta el fútbol y también va a la playa'), (-4.5649858, 'yo me gusta el fútbol y también ir a la')]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Top translations so far: [(-2.4760017, 'me gusta el fútbol y también ir a la playa endofseq'), (-3.7767177, 'me gusta el fútbol y también va a la playa endofseq'), (-4.566833, 'yo me gusta el fútbol y también ir a la playa')]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Top translations so far: [(-2.4760017, 'me gusta el fútbol y también ir a la playa endofseq'), (-3.7767177, 'me gusta el fútbol y también va a la playa endofseq'), (-4.574844, 'yo me gusta el fútbol y también ir a la playa endofseq')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'me gusta el fútbol y también ir a la playa'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "beam_search(\"I like soccer and also going to the beach\", beam_width=3,\n",
        "            verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
