{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TU71hHaX6pRv"
      },
      "outputs": [],
      "source": [
        "#Building a NLP NMT English to Spanish using RNN technique as well as Attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
        "                               extract=True)\n",
        "text = (Path(path).with_name(\"spa-eng\")/\"spa.txt\").read_text()\n",
        "\n"
      ],
      "metadata": {
        "id": "rInWzbwg61VA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we shall remove some specific tokens present only in spanish language like inverted exclamation marks, etc\n",
        "import numpy as np\n",
        "\n",
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
      ],
      "metadata": {
        "id": "TzDhIiQ2Arnm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Textvectorization layets, one per language\n",
        "vocab_size = 1000\n",
        "max_length = 50\n",
        "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length\n",
        ")\n",
        "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length\n",
        ")\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
      ],
      "metadata": {
        "id": "Z7YdHSfEBUva"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfDbqxaeBfJh",
        "outputId": "fd3b8091-118e-4054-c107-d0eafbfb6a58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer_es.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AC-_OW-SJlL",
        "outputId": "aeb9651d-4119-4071-e0f4-d0300a206fc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ],
      "metadata": {
        "id": "2sdFAoEnSLdE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
      ],
      "metadata": {
        "id": "r8O-4h_XUI22"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding the sentences and embedding layer for each language\n",
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
        "\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ],
      "metadata": {
        "id": "5VfWKbKXUNfI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
      ],
      "metadata": {
        "id": "z59CuRtKUPSz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ],
      "metadata": {
        "id": "86Gyws5IVd4a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(decoder_outputs)"
      ],
      "metadata": {
        "id": "-xQNqwXvVsv7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGyhGPOnYVYD",
        "outputId": "737f6882-adb4-4a46-eb8d-20df5e59982f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.dense.Dense at 0x7f34a065b580>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a model now\n",
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=10, validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18FyP-VeXZNf",
        "outputId": "d111d4c7-89b6-4a2d-ff36-de022195328b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3125/3125 [==============================] - 123s 34ms/step - loss: 3.2351 - accuracy: 0.3757 - val_loss: 2.6319 - val_accuracy: 0.4458\n",
            "Epoch 2/10\n",
            "3125/3125 [==============================] - 81s 26ms/step - loss: 2.2728 - accuracy: 0.4981 - val_loss: 2.0340 - val_accuracy: 0.5369\n",
            "Epoch 3/10\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 1.7818 - accuracy: 0.5789 - val_loss: 1.6879 - val_accuracy: 0.6013\n",
            "Epoch 4/10\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 1.4600 - accuracy: 0.6403 - val_loss: 1.4912 - val_accuracy: 0.6390\n",
            "Epoch 5/10\n",
            "3125/3125 [==============================] - 73s 23ms/step - loss: 1.2456 - accuracy: 0.6837 - val_loss: 1.3878 - val_accuracy: 0.6600\n",
            "Epoch 6/10\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 1.0892 - accuracy: 0.7156 - val_loss: 1.3330 - val_accuracy: 0.6718\n",
            "Epoch 7/10\n",
            "3125/3125 [==============================] - 81s 26ms/step - loss: 0.9619 - accuracy: 0.7430 - val_loss: 1.3180 - val_accuracy: 0.6775\n",
            "Epoch 8/10\n",
            "3125/3125 [==============================] - 79s 25ms/step - loss: 0.8495 - accuracy: 0.7678 - val_loss: 1.3145 - val_accuracy: 0.6816\n",
            "Epoch 9/10\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.7507 - accuracy: 0.7907 - val_loss: 1.3333 - val_accuracy: 0.6816\n",
            "Epoch 10/10\n",
            "3125/3125 [==============================] - 74s 24ms/step - loss: 0.6628 - accuracy: 0.8119 - val_loss: 1.3574 - val_accuracy: 0.6818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f34b1083d30>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pypa0vUmXrJl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we can not use model.predict here as the decoder also expects inputs from previous predictions\n",
        "#Now we shall make a fucntion to feed the decoder as well\n",
        "\n",
        "def translate(sentence_en):\n",
        "  translation = \"\"\n",
        "  for word_idx in range(max_length):\n",
        "    X = np.array([sentence_en]) #encoder input\n",
        "    X_dec = np.array([\"startofseq \" + translation])\n",
        "    y_proba = model.predict((X, X_dec))[0, word_idx]\n",
        "    predicted_word_id = np.argmax(y_proba)\n",
        "    predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "    if predicted_word == \"endofseq\":\n",
        "      break\n",
        "    translation += \" \" + predicted_word\n",
        "  return translation.strip()\n"
      ],
      "metadata": {
        "id": "8jSpit3bYJp4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"This is love.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "T98-bfUNaWhW",
        "outputId": "b6bfd3c0-e60b-4050-ad36-88a7e53c4c6e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'esto es amor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBkr_CURacJq"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}